@article{snyder2012improved,
  title={Improved thermoelectric cooling based on the Thomson effect},
  author={Snyder, G Jeffrey and Toberer, Eric S and Khanna, Raghav and Seifert, Wolfgang},
  journal={Physical Review B},
  volume={86},
  number={4},
  pages={045202},
  year={2012},
  publisher={APS},
  abstract={Traditional thermoelectric Peltier coolers exhibit a cooling limit which is primarily determined by the figure of merit, zT. Rather than a fundamental thermodynamic limit, this bound can be traced to the difficulty of maintaining thermoelectric compatibility. Self-compatibility locally maximizes the cooler's coefficient of performance for a given zT and can be achieved by adjusting the relative ratio of the thermoelectric transport properties that make up zT. In this study, we investigate the theoretical performance of thermoelectric coolers that maintain self-compatibility across the device. We find that such a device behaves very differently from a Peltier cooler, and we term self-compatible coolers “Thomson coolers” when the Fourier heat divergence is dominated by the Thomson, as opposed to the Joule, term. A Thomson cooler requires an exponentially rising Seebeck coefficient with increasing temperature, while traditional Peltier coolers, such as those used commercially, have comparatively minimal change in Seebeck coefficient with temperature. When reasonable material property bounds are placed on the thermoelectric leg, the Thomson cooler is predicted to achieve approximately twice the maximum temperature drop of a traditional Peltier cooler with equivalent figure of merit (zT). We anticipate that the development of Thomson coolers will ultimately lead to solid-state cooling to cryogenic temperatures.},
  url={https://journals.aps.org/prb/pdf/10.1103/PhysRevB.86.045202},
  categories={journal}
}

@mastersthesis{khanna2013storing,
  title={Storing Sunlight: Experimental Investigation of a Combined Sensible and Latent Heat Storage for Concentrated Solar Power Plants},
  author={Khanna, Raghav},
  year={2013},
  school={ETH-Z{\"u}rich},
  abstract={This report presents the heat transfer modelling, design, construction and experimental in- vestigation of a 40.29 KWhrth laboratory scale combined latent and sensible heat storage for concentrated solar power. The combined storage consists of a 3.97 KWhrth “latent” heat stor- age section, containing the eutectic alloy of Aluminium and Silicon, AlSi12, encapsulated in stainless steel tubes, placed on top of a 36.32 KWhrth “sensible” heat storage section, compris- ing of a packed bed of rocks. Adding a thin section of phase change material, comprising less than 7% of the total storage volume, on top of a sensible heat storage is observed to provide a highly stabilised outlet air temperature during the storage discharge cycle. Experiments show that, for a comparable range of air mass flow rates, the discharge outlet air temperature for the combined storage decreases by only 10-15 ◦C, in comparison to a 72-112 ◦C drop in tem- perature observed for a sensible only storage with the same volume, over the same time period. The combined storage concept can hence be used to provide heat at approximately constant temperatures over a significant time period for power generation or process heat applications, at little added cost, while maintaining the high thermodynamic efficiencies characteristic of thermally stratified single tank sensible heat storages.},
  url={https://www.research-collection.ethz.ch/handle/20.500.11850/154315},
  categories={master-thesis}
}

@article{zanganeh2015experimental,
  title={Experimental and numerical investigation of combined sensible-latent heat for thermal energy storage at 575 C and above},
  author={Zanganeh, G and Khanna, R and Walser, C and Pedretti, A and Haselbacher, A and Steinfeld, A},
  journal={Solar Energy},
  volume={114},
  pages={77--90},
  year={2015},
  publisher={Pergamon},
  abstract={The design, testing, and modelling of a high-temperature thermocline-type thermal energy storage (TES) are presented. The TES concept uses air as the heat-transfer fluid and combines sensible and latent heat for stabilizing the discharging outflow air temperature. A 42 kWhth lab-scale prototype of 40 cm diameter was fabricated, containing a 9 cm high layer of encapsulated phase change material (AlSi12) on top of a 127 cm high packed bed of sedimentary rocks with a mean diameter of about 3 cm. A two-phase transient heat transfer model of the thermal storage cycle was numerically formulated and experimentally validated with measured thermoclines during charging and discharging obtained with the lab-scale prototype. The thermal inertia of the experimental setup and the radial variation of void fraction due to the small tank-to-particle diameter ratio affected the validation process. The outflow air temperature during discharging was stabilized around the melting temperature of AlSi12 of 575 °C. The thermal losses stayed below 3.5% of the input energy for all the experimental runs.},
  url={http://www.sciencedirect.com/science/article/pii/S0038092X15000365},
  categories={journal}
}

@inproceedings{khanna2015beyond,
  title={Beyond point clouds-3d mapping and field parameter measurements using uavs},
  author={Khanna, Raghav and Möller, Martin and Pfeifer, Johannes and Liebisch, Frank and Walter, Achim and Siegwart, Roland},
  booktitle={Emerging Technologies \& Factory Automation (ETFA), 2015 IEEE 20th Conference on},
  pages={1--4},
  year={2015},
  url={http://ieeexplore.ieee.org/document/7301583/},
  abstract={Recent developments in Unmanned Aerial Vehicles (UAVs) have made them ideal tools for remotely monitoring agricultural fields. Complementary advancements in computer vision have enabled automated post-processing of images to generate dense 3D reconstructions in the form of point clouds. In this paper we present a monitoring pipeline that uses a readily available, low cost UAV and camera for quickly surveying a winter wheat field, generate a 3D point cloud from the collected imagery and present methods for automated crop height estimation from the extracted point cloud and compare our estimates with those using standardized techniques.},
  organization={IEEE},
  categories={conference}
}

@article{khannastudying,
  title={Studying Phenotypic Variability in Crops using a Hand-held Sensor Platform},
  author={Khanna, Raghav and Rehder, Joern and Möller, Martin and Galceran, Enric and Siegwart, Roland},
  year={2015},
  abstract={Recent developments in visual-inertial and LiDAR sensors and simultaneous localization and mapping (SLAM) enable recording and digital reconstruction of the physical world. In this paper we utilize a hand-held multi-sensor platform for remotely recording and characterizing physical properties of crops on a field. The platform consists of a visual-inertial sensor, color camera and 2D LiDAR. We syncronize the data from this platform and fuse them in a standard SLAM framework to obtain a detailed model of the field environment in the form of a 3D point cloud. Such a model is then fed into semi-automated crop parameter estimation pipelines to extract the spatio-temporal variation of physical crop height and canopy cover, which may be used to support decision making for breeding and precision agriculture. We present experimental results with data collected on a winter wheat field in Eschikon, Switzerland, showing the utility of our approach towards automating variability studies in crops.},
  url={http://flourish-project.eu/fileadmin/user_upload/publications/khanna2015iros_afr.pdf},
  categories={workshop}
}

@article{liebischflourish,
  title={Flourish-A robotic approach for automation in crop management},
  author={Liebisch, Frank and Pfeifer, Johannes and Khanna, Raghav and Lottes, Philipp and Stachniss, Cyrill and Falck, Tillmann and Sander, Slawomir and Siegwart, Roland and Walter, Achim and Galceran, Enric},
  year={2016},
  abstract={The goal of the Flourish project is to bridge the gap between the current and desired capabilities of agricultural robots by developing an adaptable robotic solution for precision farming. Thereby, combining the aerial survey capabilities of a small autono- mous multi-copter Unmanned Aerial Vehicle (UAV) with a multi-purpose agricultural Unmanned Ground Vehicle (UGV), the system will be able to survey a field from the air, perform targeted intervention on the ground, and provide detailed information for deci- sion support, all with minimal user intervention. The system can be adapted to a wide range of farm management activities and different crops by choosing different sensors, status indicators and ground treatment packages. The gathered information can be used alongside existing precision agriculture machinery, for example, by providing posi- tion maps for variable rate fertilizer application.},
  url={http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/liebisch16cbaws.pdf},
  categories={conference}
  }

@inproceedings{pfeifer2016towards,
  title={Towards automatic UAV data interpretation for precision farming},
  author={Pfeifer, Johannes and Khanna, Raghav and Dragos, C and Popovic, Marija and Galceran, Enric and Kirchgessner, Norbert and Walter, Achim and Siegwart, Roland and Liebisch, Frank},
  booktitle={CIGR-AgEng conference. Aarhus, Denmark},
  abstract={Background: The EU-project Flourish intends to establish an autonomously operating precision farming system based on the interaction between unmanned ground vehicles (UGVs) and unmanned aerial vehicles (UAVs). For effective mission planning and site-specific ground intervention by the UGV, the growth, mineral nutrition, weed, and health status of the crop field must be evaluated efficiently. In this regard, the survey capabilities of UAVs can substantially leverage the economic performance and ecological sustainability of precision farming systems.
    Methods: Our approach is based on ‘sufficient performance ranges’ (SPRs), which represent the expected optimal performance of phenotypic traits such as spectral indicators and growth parameters like canopy cover and crop height. Together with a priori data, such as weather situation and soil fertility maps, the UAV derived maps allow for the detection of deviations from sufficient crop development. Detected deviations are interpreted using decision tree models. Our models encompass upstream and downstream decisions necessary for scheduling site-specific and efficient ground interventions during the whole management sequence of a growing season, such as fertilizer input or weed control.
    Results: This contribution presents initial results for field monitoring via UAVs. The performance of our approach is supported by ground truth data, such as crop height, canopy cover and spectral indices from sugar beets collected in 2015. Effects of variable soil fertility, weed pressure and drought stress are presented.
    Conclusion: The initial results support the proposed intention to derive appropriate management decisions for stabilizing crop yield and quality while minimizing farm inputs.},
    url={http://flourish-project.eu/fileadmin/user_upload/publications/2016_Pfeifer-UAV_data_interpretation.pdf},
  year={2016},
  categories={conference}
}

@inproceedings{lottes2017uav,
  title={UAV-based crop and weed classification for smart farming},
  author={Lottes, Philipp and Khanna, Raghav and Pfeifer, Johannes and Siegwart, Roland and Stachniss, Cyrill},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3024--3031},
  year={2017},
  abstract={Unmanned aerial vehicles (UAVs) and other robots in smart farming applications offer the potential to monitor farm land on a per-plant basis, which in turn can reduce the amount of herbicides and pesticides that must be applied. A central information for the farmer as well as for autonomous agriculture robots is the knowledge about the type and distribu- tion of the weeds in the field. In this regard, UAVs offer excellent survey capabilities at low cost. In this paper, we address the problem of detecting value crops such as sugar beets as well as typical weeds using a camera installed on a light-weight UAV. We propose a system that performs vegetation detection, plant-tailored feature extraction, and classification to obtain an estimate of the distribution of crops and weeds in the field. We implemented and evaluated our system using UAVs on two farms, one in Germany and one in Switzerland and demonstrate that our approach allows for analyzing the field and classifying individual plants.},
  url={http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/lottes17icra.pdf},
  organization={IEEE},
  categories={conference}
}

@inproceedings{khanna2017field,
  title={On field radiometric calibration for multispectral cameras},
  author={Khanna, Raghav and Sa, Inkyu and Nieto, Juan and Siegwart, Roland},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={6503--6509},
  year={2017},
  url={http://flourish-project.eu/fileadmin/user_upload/publications/2017-icra-khanna.pdf},
  abstract={Perception systems for outdoor robotics have to deal with varying environmental conditions. Variations in illumination in particular, are currently the biggest challenge for vision-based perception. In this paper we present an approach for radiometric characterization of multispectral cameras. To enable spatio-temporal mapping we also present a procedure for in-situ illumination estimation, resulting in radiometric calibration of the collected images. In contrast to current approaches, we present a purely data driven, parameter free approach, based on maximum likelihood estimation which can be performed entirely on the field, without requiring specialised laboratory equipment. Our routine requires three simple datasets which are easily acquired using most modern multispectral cameras. We evaluate the framework with a cost-effective snapshot multispectral camera. The results show that our method enables the creation of quatitatively accurate relative reflectance images with challenging on field calibration datasets under a variety of ambient conditions.},
  organization={IEEE},
  categories={conference}
}

@article{sa2017build,
  title={Build your own visual-inertial odometry aided cost-effective and open-source autonomous drone},
  author={Sa, Inkyu and Kamel, Mina and Burri, Michael and Bloesch, Michael and Khanna, Raghav and Popovic, Marija and Nieto, Juan and Siegwart, Roland},
  journal={arXiv preprint arXiv:1708.06652},
  abstract={This paper describes an approach to building a cost-effective and research grade visual-inertial odometry aided vertical taking-off and landing (VTOL) platform. We utilize an off-the-shelf visual-inertial sensor, an onboard computer, and a quadrotor platform that are factory-calibrated and mass-produced, thereby sharing similar hardware and sensor specifications (e.g., mass, dimensions, intrinsic and extrinsic of camera-IMU systems, and signal-to-noise ratio). We then perform a system calibration and identification enabling the use of our visual-inertial odometry, multi-sensor fusion, and model predictive control frameworks with the off-the-shelf products. This implies that we can partially avoid tedious parameter tuning procedures for building a full system. The complete system is extensively evaluated both indoors using a motion capture system and outdoors using a laser tracker while performing hover and step responses, and trajectory following tasks in the presence of external wind disturbances. We achieve root-mean-square (RMS) pose errors between a reference and actual trajectories of 0.036m, while performing hover. We also conduct relatively long distance flight (~180m) experiments on a farm site and achieve 0.82% drift error of the total distance flight. This paper conveys the insights we acquired about the platform and sensor module and returns to the community as open-source code with tutorial documentation.},
  url={https://arxiv.org/abs/1708.06652},
  year={2017},
  code={https://github.com/ethz-asl/mav_dji_ros_interface},
  categories={conference}
}

@article{sa2017dynamic,
  title={Dynamic System Identification, and Control for a cost effective open-source VTOL MAV},
  author={Sa, Inkyu and Kamel, Mina and Khanna, Raghav and Popovic, Marija and Nieto, Juan and Siegwart, Roland},
  journal={arXiv preprint arXiv:1701.08623},
  year={2017},
  url={https://arxiv.org/abs/1701.08623},
  abstract={This paper describes dynamic system identification, and full control of a cost-effective vertical take-off and landing (VTOL) multi-rotor micro-aerial vehicle (MAV) --- DJI Matrice 100. The dynamics of the vehicle and autopilot controllers are identified using only a built-in IMU and utilized to design a subsequent model predictive controller (MPC). Experimental results for the control performance are evaluated using a motion capture system while performing hover, step responses, and trajectory following tasks in the present of external wind disturbances. We achieve root-mean-square (RMS) errors between the reference and actual trajectory of x=0.021m, y=0.016m, z=0.029m, roll=0.392deg, pitch=0.618deg, and yaw=1.087deg while performing hover. This paper also conveys the insights we have gained about the platform and returned to the community through open-source code, and documentation.},
  code={https://github.com/ethz-asl/mav_dji_ros_interface}
}

@article{sa2017weednet,
  title={weedNet: Dense Semantic Weed Classification Using Multispectral Images and MAV for Smart Farming},
  author={Sa, Inkyu and Chen, Zetao and Popovic, Marija and Khanna, Raghav and Liebisch, Frank and Nieto, Juan and Siegwart, Roland},
  journal={arXiv preprint arXiv:1709.03329},
  abstract={Selective weed treatment is a critical step in autonomous crop management as related to crop health and yield. However, a key challenge is reliable, and accurate weed detection to minimize damage to surrounding plants. In this paper, we present an approach for dense semantic weed classification with multispectral images collected by a micro aerial vehicle (MAV). We use the recently developed encoder-decoder cascaded Convolutional Neural Network (CNN), Segnet, that infers dense semantic classes while allowing any number of input image channels and class balancing with our sugar beet and weed datasets. To obtain training datasets, we established an experimental field with varying herbicide levels resulting in field plots containing only either crop or weed, enabling us to use the Normalized Difference Vegetation Index (NDVI) as a distinguishable feature for automatic ground truth generation. We train 6 models with different numbers of input channels and condition (fine-tune) it to achieve about 0.8 F1-score and 0.78 Area Under the Curve (AUC) classification metrics. For model deployment, an embedded GPU system (Jetson TX2) is tested for MAV integration. Dataset used in this paper is released to support the community and future work.},
  url={https://arxiv.org/abs/1709.03329},
  year={2017},
  code={https://github.com/inkyusa/weedNet},
  categories={submitted}
}

@inproceedings{sommer2017calibration_devices,
  title={A Low-Cost System for High-Rate, High-Accuracy Temporal Calibration for LIDARs and Cameras},
  author={Sommer, Hannes and Khanna, Raghav and Gilitschenski, Igor and Taylor, Zachary and Siegwart, Roland and Nieto, Juan},
  booktitle={Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International Conference on},
  pages={},
  year={2017},
  abstract={Deployment of camera and laser based motion estimation systems for controlling platforms operating at high speeds, such as cars or trains, is posing increasingly challenging precision requirements on the temporal calibration of these sensors. In this work, we demonstrate a simple, low-cost system for calibrating any combination of cameras and time of flight LIDARs with respect to the CPU clock (and therefore, also to each other). The newly proposed device is based on widely available off-the-shelf components, such as the Raspberry Pi 3, which is synchronized using the Precision Time Protocol (PTP) with respect to the CPU of the sensor carrying system. The obtained accuracy can be shown to be below 0.1 ms per measurement for LIDARs and below minimal exposure time per image for cameras. It outperforms state-of-the-art approaches also not relying on hardware synchronization by more than a factor of 10 in precision. Moreover, the entire process can be carried out at a high rate allowing the study of how offsets evolve over time. In our analysis, we demonstrate how each building block of the system contributes to this accuracy and validate the obtained results using real-world data.},
  url={http://flourish-project.eu/fileadmin/user_upload/publications/2017-iros-sommer.pdf},
  code={https://github.com/ethz-asl/cuckoo_time_translator},
  organization={IEEE},
  categories={conference}
}